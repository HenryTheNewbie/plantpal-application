{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0cbb90-bc4e-41a8-a574-96f3f2826a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.13.0 in c:\\users\\henry\\myenv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0; platform_system == \"Windows\" in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (24.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.67.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (18.1.1)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (41.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.20.3)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.31.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.32.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.0.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.44.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\henry\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\henry\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\henry\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\henry\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.1.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\henry\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\henry\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (5.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\henry\\myenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (8.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\henry\\myenv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.2.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\henry\\myenv\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0; platform_system == \"Windows\"->tensorflow==2.13.0) (3.20.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 24.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflite-support==0.4.3 in c:\\users\\henry\\myenv\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (24.3.25)\n",
      "Requirement already satisfied: protobuf<4,>=3.18.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (3.20.3)\n",
      "Requirement already satisfied: pybind11>=2.6.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (2.13.6)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (1.24.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (2.1.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\henry\\myenv\\lib\\site-packages (from tflite-support==0.4.3) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\henry\\myenv\\lib\\site-packages (from sounddevice>=0.4.4->tflite-support==0.4.3) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\henry\\myenv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support==0.4.3) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 24.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0\n",
    "!pip install tflite-support==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbcb2c8-7bb8-43a3-b641-5ead351cb535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6800 images belonging to 8 classes.\n",
      "Found 1200 images belonging to 8 classes.\n",
      "Epoch 1/50\n",
      "106/106 [==============================] - 178s 2s/step - loss: 0.9759 - accuracy: 0.7504 - val_loss: 0.4455 - val_accuracy: 0.9332\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 144s 1s/step - loss: 0.4774 - accuracy: 0.9028 - val_loss: 0.3401 - val_accuracy: 0.9566\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 138s 1s/step - loss: 0.3872 - accuracy: 0.9299 - val_loss: 0.2779 - val_accuracy: 0.9722\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 135s 1s/step - loss: 0.3398 - accuracy: 0.9420 - val_loss: 0.2525 - val_accuracy: 0.9722\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 145s 1s/step - loss: 0.3095 - accuracy: 0.9463 - val_loss: 0.2371 - val_accuracy: 0.9722\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 148s 1s/step - loss: 0.2867 - accuracy: 0.9510 - val_loss: 0.2119 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 140s 1s/step - loss: 0.2629 - accuracy: 0.9538 - val_loss: 0.1994 - val_accuracy: 0.9757\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.2435 - accuracy: 0.9577 - val_loss: 0.1885 - val_accuracy: 0.9783\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.2311 - accuracy: 0.9607 - val_loss: 0.1836 - val_accuracy: 0.9757\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 135s 1s/step - loss: 0.2305 - accuracy: 0.9575 - val_loss: 0.1759 - val_accuracy: 0.9800\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.2182 - accuracy: 0.9583 - val_loss: 0.1680 - val_accuracy: 0.9757\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.2091 - accuracy: 0.9618 - val_loss: 0.1591 - val_accuracy: 0.9792\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 135s 1s/step - loss: 0.1860 - accuracy: 0.9697 - val_loss: 0.1638 - val_accuracy: 0.9731\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.1840 - accuracy: 0.9694 - val_loss: 0.1498 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 141s 1s/step - loss: 0.1831 - accuracy: 0.9641 - val_loss: 0.1623 - val_accuracy: 0.9696\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 137s 1s/step - loss: 0.1823 - accuracy: 0.9669 - val_loss: 0.1376 - val_accuracy: 0.9792\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 136s 1s/step - loss: 0.1707 - accuracy: 0.9684 - val_loss: 0.1376 - val_accuracy: 0.9792\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 137s 1s/step - loss: 0.1649 - accuracy: 0.9715 - val_loss: 0.1329 - val_accuracy: 0.9774\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 173s 2s/step - loss: 0.1663 - accuracy: 0.9685 - val_loss: 0.1288 - val_accuracy: 0.9800\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 154s 1s/step - loss: 0.1633 - accuracy: 0.9693 - val_loss: 0.1414 - val_accuracy: 0.9722\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 151s 1s/step - loss: 0.1574 - accuracy: 0.9711 - val_loss: 0.1265 - val_accuracy: 0.9757\n",
      "Epoch 22/50\n",
      " 65/106 [=================>............] - ETA: 52s - loss: 0.1542 - accuracy: 0.9701"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m\n\u001b[0;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m     81\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     82\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping and learning rate reduction\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     94\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/MobileNetV2_Disease_Detection_Model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths and set hyperparameters\n",
    "train_data_dir = '../data/train_disease'\n",
    "\n",
    "# Function to exclude the '.ipynb_checkpoints' directory\n",
    "def filter_folders(directory):\n",
    "    return [folder for folder in os.listdir(directory) if folder != '.ipynb_checkpoints']\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "learning_rate = 0.0005  # Reduced learning rate for smoother convergence\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Data Preprocessing with 15% validation split and enhanced augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.8, 1.2],  # Adjust brightness for more robust training\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.15  # 15% for validation\n",
    ")\n",
    "\n",
    "# No augmentation for validation data, just rescaling\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.15)\n",
    "\n",
    "# Load training data (85% training)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # 85% training split\n",
    "    classes=filter_folders(train_data_dir)\n",
    ")\n",
    "\n",
    "# Load validation data (15% validation)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # 15% validation split\n",
    "    classes=filter_folders(train_data_dir)\n",
    ")\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model, excluding its top layers\n",
    "base_model = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Set base layers to train partially (fine-tuning), using gradual unfreezing\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model (Custom Head)\n",
    "model = models.Sequential([\n",
    "    base_model,  # Pre-trained MobileNetV2 as feature extractor\n",
    "    layers.GlobalAveragePooling2D(),  # Pooling layer\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),  # L2 regularization to prevent overfitting\n",
    "    layers.Dropout(0.3),  # Dropout for regularization\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping and learning rate reduction\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('../models/MobileNetV2_Disease_Detection_Model.keras')\n",
    "\n",
    "# Convert to TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('../models/MobileNetV2_Disease_Detection_Model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Plot the training and validation accuracy/loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 14. Optionally, print the number of samples\n",
    "print(f\"Number of training samples: {train_generator.samples}\")\n",
    "print(f\"Number of validation samples: {validation_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be36776-f3b2-44da-b1fd-98f2beca47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata populated successfully.\n"
     ]
    }
   ],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support.metadata_writers import image_classifier\n",
    "import os\n",
    "\n",
    "# Load your TensorFlow Lite model file\n",
    "model_file = \"../models/MobileNetV2_Disease_Detection_Model.tflite\"\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"MobileV2 Disease Detection Model\"\n",
    "model_meta.description = (\"This model identifies plant diseases based on input images. \"\n",
    "                          \"It classifies the plant into zero or more known categories of plant diseases.\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.license = (\"Apache License, Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")\n",
    "\n",
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"input_image\"\n",
    "input_meta.description = (\n",
    "    \"Input image for plant disease identification. The image should be resized to 224 x 224 pixels \"\n",
    "    \"with three RGB channels. Each value in the tensor is a single byte between 0 and 255.\")\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "\n",
    "# Input normalization settings\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [0.0]  # Normalization mean\n",
    "input_normalization.options.std = [255.0]   \n",
    "input_meta.processUnits = [input_normalization]\n",
    "\n",
    "# Input statistics\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats\n",
    "\n",
    "# Creates output info.\n",
    "output_meta = _metadata_fb.TensorMetadataT()\n",
    "output_meta.name = \"plant_probability\"\n",
    "output_meta.description = \"Probabilities corresponding to different plant disease classifications.\"\n",
    "output_meta.content = _metadata_fb.ContentT()\n",
    "output_meta.content.contentProperties = _metadata_fb.FeaturePropertiesT()\n",
    "output_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "\n",
    "# Output statistics\n",
    "output_stats = _metadata_fb.StatsT()\n",
    "output_stats.max = [1.0]\n",
    "output_stats.min = [0.0]\n",
    "output_meta.stats = output_stats\n",
    "\n",
    "# Associated label file\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = os.path.basename(\"disease_labels.txt\")  # Ensure the filename matches your labels file\n",
    "label_file.description = \"Labels for plant diseases that the model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_meta.associatedFiles = [label_file]\n",
    "\n",
    "# Creates subgraph info.\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [output_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "# Creates Flatbuffer metadata\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()\n",
    "\n",
    "# Pack metadata and associated files into the model\n",
    "populator = _metadata.MetadataPopulator.with_model_file(model_file)\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.load_associated_files([\"disease_labels.txt\"])  # Ensure this file exists in the specified location\n",
    "populator.populate()\n",
    "\n",
    "# Verify the metadata generated by the populator\n",
    "print(\"Metadata populated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ccff6de-a006-4420-a77f-7b27c1aa94af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying image: blight_testing_008.JPG\n",
      "Image: blight_testing_008.JPG, Predicted Class: Blight, Confidence: 1.0000\n",
      "Classifying image: blight_testing_009.JPG\n",
      "Image: blight_testing_009.JPG, Predicted Class: Blight, Confidence: 1.0000\n",
      "Classifying image: blight_testing_010.JPG\n",
      "Image: blight_testing_010.JPG, Predicted Class: Blight, Confidence: 0.9999\n",
      "Classifying image: blight_testing_011.JPG\n",
      "Image: blight_testing_011.JPG, Predicted Class: Blight, Confidence: 0.9967\n",
      "Classifying image: blight_testing_012.JPG\n",
      "Image: blight_testing_012.JPG, Predicted Class: Blight, Confidence: 0.9999\n",
      "Classifying image: blight_testing_013.JPG\n",
      "Image: blight_testing_013.JPG, Predicted Class: Blight, Confidence: 0.9006\n",
      "Classifying image: blight_testing_014.JPG\n",
      "Image: blight_testing_014.JPG, Predicted Class: Bacterial Spot, Confidence: 0.9581\n",
      "Classifying image: blight_testing_015.JPG\n",
      "Image: blight_testing_015.JPG, Predicted Class: Bacterial Spot, Confidence: 0.5903\n",
      "Classifying image: blight_testing_016.JPG\n",
      "Image: blight_testing_016.JPG, Predicted Class: Blight, Confidence: 0.8153\n",
      "Classifying image: blight_testing_017.JPG\n",
      "Image: blight_testing_017.JPG, Predicted Class: Blight, Confidence: 0.7339\n",
      "Classifying image: blight_testing_018.JPG\n",
      "Image: blight_testing_018.JPG, Predicted Class: Mold, Confidence: 0.8901\n",
      "Classifying image: healthy_testing_019.JPG\n",
      "Image: healthy_testing_019.JPG, Predicted Class: Blight, Confidence: 0.9518\n",
      "Classifying image: healthy_testing_020.JPG\n",
      "Image: healthy_testing_020.JPG, Predicted Class: Blight, Confidence: 0.9740\n",
      "Classifying image: healthy_testing_021.JPG\n",
      "Image: healthy_testing_021.JPG, Predicted Class: Healthy, Confidence: 0.9057\n",
      "Classifying image: healthy_testing_022.JPG\n",
      "Image: healthy_testing_022.JPG, Predicted Class: Healthy, Confidence: 0.5624\n",
      "Classifying image: healthy_testing_023.JPG\n",
      "Image: healthy_testing_023.JPG, Predicted Class: Healthy, Confidence: 0.8324\n",
      "Classifying image: healthy_testing_024.JPG\n",
      "Image: healthy_testing_024.JPG, Predicted Class: Blight, Confidence: 0.4931\n",
      "Classifying image: rust_testing_001.JPG\n",
      "Image: rust_testing_001.JPG, Predicted Class: Rust, Confidence: 0.9731\n",
      "Classifying image: rust_testing_002.JPG\n",
      "Image: rust_testing_002.JPG, Predicted Class: Rust, Confidence: 0.9956\n",
      "Classifying image: rust_testing_003.JPG\n",
      "Image: rust_testing_003.JPG, Predicted Class: Rust, Confidence: 0.6248\n",
      "Classifying image: rust_testing_004.JPG\n",
      "Image: rust_testing_004.JPG, Predicted Class: Rust, Confidence: 0.9916\n",
      "Classifying image: rust_testing_005.JPG\n",
      "Image: rust_testing_005.JPG, Predicted Class: Rust, Confidence: 0.9995\n",
      "Classifying image: rust_testing_006.JPG\n",
      "Image: rust_testing_006.JPG, Predicted Class: Rust, Confidence: 0.9431\n",
      "Classifying image: rust_testing_007.JPG\n",
      "Image: rust_testing_007.JPG, Predicted Class: Rust, Confidence: 0.9999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../models/MobileNetV2_Disease_Detection_Model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224))  # Resize to match model input\n",
    "    img_array = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array.astype(np.float32)\n",
    "\n",
    "# Function to get class names based on disease_labels.txt\n",
    "def get_class_names():\n",
    "    return [\n",
    "        'Bacterial Spot',\n",
    "        'Black Rot',\n",
    "        'Blight',\n",
    "        'Healthy',\n",
    "        'Leaf Scorch',\n",
    "        'Mold',\n",
    "        'Powdery Mildew',\n",
    "        'Rust'\n",
    "    ]\n",
    "\n",
    "# Main function to classify images in a directory\n",
    "def classify_images_in_directory(directory):\n",
    "    # Get the class names based on the predefined list\n",
    "    class_names = get_class_names()  # Reflects the disease classes\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for img_file in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_file)\n",
    "        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
    "            print(f\"Classifying image: {img_file}\")  # Debugging line\n",
    "            img_array = preprocess_image(img_path)\n",
    "\n",
    "            # Set the input tensor\n",
    "            interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "\n",
    "            # Run the model\n",
    "            interpreter.invoke()\n",
    "\n",
    "            # Get the output tensor\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            confidence_scores = output_data[0]\n",
    "\n",
    "            # Get predicted class index\n",
    "            predicted_class_index = np.argmax(confidence_scores)\n",
    "            confidence = confidence_scores[predicted_class_index]\n",
    "\n",
    "            # Print the class name and confidence\n",
    "            print(f\"Image: {img_file}, Predicted Class: {class_names[predicted_class_index]}, Confidence: {confidence:.4f}\")\n",
    "\n",
    "# Change this directory to the path where your images are stored\n",
    "image_directory = '../data/test_disease' \n",
    "classify_images_in_directory(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61228f05-1c43-47cf-b546-5e3e3005fbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
